# Generative-Modeling-for-Skin-Lesion-Synthesis
**Objective:**
1. Train a Vector-Quantized Variational Autoencoder (VQ-VAE) on the skin lesion dataset to efficiently encode and decode high-dimensional image data while capturing meaningful latent representations. 
2. Train an Auto-Regressive Model of your choice to generate new, realistic images based on the learned latent space representations.

**Dataset:** ISIC dataset. \
Visualization can be observed below: \
![image](https://github.com/user-attachments/assets/61cac1be-9823-4bf3-89ed-1ea8b23a32c7)

**Reconstructed images on Test Data after 2500 Epochs:** \
![image](https://github.com/user-attachments/assets/640ee2c1-ec24-4d19-a633-8f482c14828d)
![test2](https://github.com/user-attachments/assets/d40d924f-fddf-4c32-aa83-146afe83df52)

**Generated images using PixelCNN:** \
![pcnn1 (1)](https://github.com/user-attachments/assets/1c6dcc73-9b97-4b68-b0b9-d06c039a66eb)
![pcnn2 (7)](https://github.com/user-attachments/assets/c7feac0f-2249-4e08-9ff6-d31efac70715)
